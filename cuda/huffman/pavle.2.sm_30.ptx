







.version 6.4
.target sm_30
.address_size 64


.extern .shared .align 4 .b8 sm[];

.entry _Z26vlc_encode_kernel_sm64huffPjPKjS1_S_S_S_S_S_(
.param .u64 _Z26vlc_encode_kernel_sm64huffPjPKjS1_S_S_S_S_S__param_0,
.param .u64 _Z26vlc_encode_kernel_sm64huffPjPKjS1_S_S_S_S_S__param_1,
.param .u64 _Z26vlc_encode_kernel_sm64huffPjPKjS1_S_S_S_S_S__param_2,
.param .u64 _Z26vlc_encode_kernel_sm64huffPjPKjS1_S_S_S_S_S__param_3,
.param .u64 _Z26vlc_encode_kernel_sm64huffPjPKjS1_S_S_S_S_S__param_4,
.param .u64 _Z26vlc_encode_kernel_sm64huffPjPKjS1_S_S_S_S_S__param_5,
.param .u64 _Z26vlc_encode_kernel_sm64huffPjPKjS1_S_S_S_S_S__param_6,
.param .u64 _Z26vlc_encode_kernel_sm64huffPjPKjS1_S_S_S_S_S__param_7
)
{
.reg .pred %p<12>;
.reg .b32 %r<136>;
.reg .b64 %rd<33>;

	.shared .align 4 .u32 _ZZ26vlc_encode_kernel_sm64huffPjPKjS1_S_S_S_S_S_E5kcmax;

ld.param.u64 %rd5, [_Z26vlc_encode_kernel_sm64huffPjPKjS1_S_S_S_S_S__param_0];
ld.param.u64 %rd6, [_Z26vlc_encode_kernel_sm64huffPjPKjS1_S_S_S_S_S__param_1];
ld.param.u64 %rd7, [_Z26vlc_encode_kernel_sm64huffPjPKjS1_S_S_S_S_S__param_2];
ld.param.u64 %rd3, [_Z26vlc_encode_kernel_sm64huffPjPKjS1_S_S_S_S_S__param_6];
ld.param.u64 %rd4, [_Z26vlc_encode_kernel_sm64huffPjPKjS1_S_S_S_S_S__param_7];
cvta.to.global.u64 %rd8, %rd5;
mov.u32 %r1, %ntid.x;
mov.u32 %r25, %ctaid.x;
mov.u32 %r2, %tid.x;
mad.lo.s32 %r26, %r1, %r25, %r2;
cvta.to.global.u64 %rd9, %rd6;
mul.wide.u32 %rd10, %r2, 4;
add.s64 %rd11, %rd9, %rd10;
ld.global.u32 %r27, [%rd11];
shl.b32 %r28, %r2, 2;
mov.u32 %r29, sm;
add.s32 %r3, %r29, %r28;
st.shared.u32 [%r3], %r27;
cvta.to.global.u64 %rd12, %rd7;
add.s64 %rd13, %rd12, %rd10;
ld.global.u32 %r30, [%rd13];
st.shared.u32 [%r3+1024], %r30;
cvt.u64.u32	%rd1, %r26;
mul.wide.u32 %rd14, %r26, 4;
add.s64 %rd15, %rd8, %rd14;
ld.global.u32 %r4, [%rd15];
bar.sync 0;
shr.u32 %r31, %r4, 22;
and.b32 %r32, %r31, 1020;
add.s32 %r34, %r29, %r32;
ld.shared.u8 %r35, [%r34+1024];
ld.shared.u32 %rd16, [%r34];
shr.u32 %r36, %r4, 14;
and.b32 %r37, %r36, 1020;
add.s32 %r38, %r29, %r37;
ld.shared.u8 %r39, [%r38+1024];
shl.b64 %rd17, %rd16, %r39;
ld.shared.u32 %rd18, [%r38];
or.b64 %rd19, %rd17, %rd18;
add.s32 %r40, %r39, %r35;
shr.u32 %r41, %r4, 6;
and.b32 %r42, %r41, 1020;
add.s32 %r43, %r29, %r42;
ld.shared.u8 %r44, [%r43+1024];
shl.b64 %rd20, %rd19, %r44;
ld.shared.u32 %rd21, [%r43];
or.b64 %rd22, %rd20, %rd21;
add.s32 %r45, %r44, %r40;
shl.b32 %r46, %r4, 2;
and.b32 %r47, %r46, 1020;
add.s32 %r48, %r29, %r47;
ld.shared.u8 %r49, [%r48+1024];
shl.b64 %rd23, %rd22, %r49;
ld.shared.u32 %rd24, [%r48];
or.b64 %rd2, %rd23, %rd24;
add.s32 %r5, %r49, %r45;
st.shared.u32 [%r3+2048], %r5;
bar.sync 0;
shr.u32 %r130, %r1, 1;
mov.u32 %r132, 1;
setp.eq.s32	%p1, %r130, 0;
@%p1 bra BB0_5;

shl.b32 %r52, %r2, 1;
mov.u32 %r132, 1;
add.s32 %r7, %r52, 1;
add.s32 %r8, %r52, 2;

BB0_2:
bar.sync 0;
setp.ge.u32	%p2, %r2, %r130;
@%p2 bra BB0_4;

mad.lo.s32 %r53, %r132, %r7, 255;
mad.lo.s32 %r54, %r132, %r8, 255;
shl.b32 %r55, %r53, 2;
and.b32 %r56, %r55, 1020;
add.s32 %r58, %r56, %r29;
shl.b32 %r59, %r54, 2;
and.b32 %r60, %r59, 1020;
add.s32 %r61, %r60, %r29;
ld.shared.u32 %r62, [%r61+2048];
ld.shared.u32 %r63, [%r58+2048];
add.s32 %r64, %r62, %r63;
st.shared.u32 [%r61+2048], %r64;

BB0_4:
shl.b32 %r132, %r132, 1;
shr.u32 %r130, %r130, 1;
setp.ne.s32	%p3, %r130, 0;
@%p3 bra BB0_2;

BB0_5:
setp.ne.s32	%p4, %r2, 0;
@%p4 bra BB0_7;

shl.b32 %r65, %r1, 2;
add.s32 %r67, %r65, %r29;
mov.u32 %r68, 0;
st.shared.u32 [%r67+2044], %r68;

BB0_7:
setp.lt.u32	%p5, %r1, 2;
@%p5 bra BB0_12;

shl.b32 %r70, %r2, 1;
mov.u32 %r133, 1;
add.s32 %r14, %r70, 1;
add.s32 %r15, %r70, 2;

BB0_9:
shr.u32 %r132, %r132, 1;
bar.sync 0;
setp.ge.u32	%p6, %r2, %r133;
@%p6 bra BB0_11;

mad.lo.s32 %r71, %r132, %r14, 255;
mad.lo.s32 %r72, %r132, %r15, 255;
shl.b32 %r73, %r71, 2;
and.b32 %r74, %r73, 1020;
add.s32 %r76, %r74, %r29;
ld.shared.u32 %r77, [%r76+2048];
shl.b32 %r78, %r72, 2;
and.b32 %r79, %r78, 1020;
add.s32 %r80, %r79, %r29;
ld.shared.u32 %r81, [%r80+2048];
st.shared.u32 [%r76+2048], %r81;
ld.shared.u32 %r82, [%r80+2048];
add.s32 %r83, %r82, %r77;
st.shared.u32 [%r80+2048], %r83;

BB0_11:
shl.b32 %r133, %r133, 1;
setp.lt.u32	%p7, %r133, %r1;
@%p7 bra BB0_9;

BB0_12:
bar.sync 0;
add.s32 %r84, %r1, -1;
ld.shared.u32 %r20, [%r3+2048];
setp.ne.s32	%p8, %r2, %r84;
@%p8 bra BB0_14;

add.s32 %r85, %r20, %r5;
cvta.to.global.u64 %rd25, %rd4;
mul.wide.u32 %rd26, %r25, 4;
add.s64 %rd27, %rd25, %rd26;
st.global.u32 [%rd27], %r85;
shr.u32 %r87, %r85, 5;
st.shared.u32 [_ZZ26vlc_encode_kernel_sm64huffPjPKjS1_S_S_S_S_S_E5kcmax], %r87;

BB0_14:
shr.u32 %r21, %r20, 5;
mov.u32 %r88, 0;
st.shared.u32 [%r3+2048], %r88;
bar.sync 0;
and.b32 %r89, %r20, 31;
mov.u32 %r90, 32;
sub.s32 %r91, %r90, %r89;
min.u32 %r92, %r91, %r5;
sub.s32 %r135, %r5, %r92;
shr.u64 %rd28, %rd2, %r135;
cvt.u32.u64	%r93, %rd28;
shl.b32 %r94, %r21, 2;
add.s32 %r96, %r94, %r29;
add.s32 %r97, %r96, 2048;
sub.s32 %r98, %r91, %r92;
shl.b32 %r99, %r93, %r98;
atom.shared.or.b32 %r100, [%r97], %r99;
setp.eq.s32	%p9, %r5, %r92;
@%p9 bra BB0_16;

min.u32 %r102, %r90, %r135;
sub.s32 %r135, %r135, %r102;
shr.u64 %rd29, %rd2, %r135;
cvt.u32.u64	%r103, %rd29;
mov.u32 %r104, 1;
shl.b32 %r105, %r104, %r102;
add.s32 %r106, %r105, -1;
and.b32 %r107, %r103, %r106;
add.s32 %r111, %r96, 2052;
sub.s32 %r112, %r90, %r102;
shl.b32 %r113, %r107, %r112;
atom.shared.or.b32 %r114, [%r111], %r113;

BB0_16:
setp.eq.s32	%p10, %r135, 0;
@%p10 bra BB0_18;

mov.u32 %r115, 1;
shl.b32 %r116, %r115, %r135;
add.s32 %r117, %r116, -1;
cvt.u32.u64	%r118, %rd2;
and.b32 %r119, %r117, %r118;
add.s32 %r123, %r96, 2056;
sub.s32 %r125, %r90, %r135;
shl.b32 %r126, %r119, %r125;
atom.shared.or.b32 %r127, [%r123], %r126;

BB0_18:
bar.sync 0;
ld.shared.u32 %r128, [_ZZ26vlc_encode_kernel_sm64huffPjPKjS1_S_S_S_S_S_E5kcmax];
setp.gt.u32	%p11, %r2, %r128;
@%p11 bra BB0_20;

ld.shared.u32 %r129, [%r3+2048];
cvta.to.global.u64 %rd30, %rd3;
shl.b64 %rd31, %rd1, 2;
add.s64 %rd32, %rd30, %rd31;
st.global.u32 [%rd32], %r129;

BB0_20:
ret;
}


